{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\n","  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n","Collecting beautifulsoup4 (from gdown)\n","  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n","Collecting filelock (from gdown)\n","  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: requests[socks] in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from gdown) (4.66.1)\n","Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n","  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests[socks]->gdown) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests[socks]->gdown) (2023.11.17)\n","Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n","  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n","Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n","Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n","Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n","Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n","Installing collected packages: soupsieve, PySocks, filelock, beautifulsoup4, gdown\n","Successfully installed PySocks-1.7.1 beautifulsoup4-4.12.3 filelock-3.14.0 gdown-5.2.0 soupsieve-2.5\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory limit set for GPU\n"]}],"source":["import tensorflow as tf\n","\n","# Kiểm tra xem có GPU có sẵn không\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Kiểm tra và ghi nhớ thiết bị ảo\n","        tf.config.experimental.set_virtual_device_configuration(\n","            gpus[0],\n","            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=30096)])  # Giới hạn bộ nhớ là 4GB\n","        print(\"Memory limit set for GPU\")\n","    except RuntimeError as e:\n","        print(e)\n","else:\n","    print(\"No GPU available\")\n","\n","# Thực hiện các bước tiếp theo ở đây sau khi cấu hình đã được thiết lập\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1u_2rWoM0mrSMaNS9kiUPlF-s98RO66-F\n","To: /home/trungct/Duyborrow/notebook/chatbot.csv\n","100%|██████████| 7.08M/7.08M [00:00<00:00, 92.1MB/s]\n"]},{"data":{"text/plain":["'chatbot.csv'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import gdown\n","\n","\n","url = f\"https://drive.google.com/uc?id=1u_2rWoM0mrSMaNS9kiUPlF-s98RO66-F\"\n","\n","output = \"chatbot.csv\"\n","  # Specify the name of the downloaded file\n","\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gdown\n","\n","\n","url = f\"https://drive.google.com/uc?id=1VObqagdYTyyYLeaK4uQHsW72nYujw4DY\"\n","\n","output = \"vistral.zip\"\n","  # Specify the name of the downloaded file\n","\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import zipfile\n","import os\n","def unzip_folder(zip_path, extract_to):\n","    if not os.path.exists(extract_to):\n","        os.makedirs(extract_to)\n","        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","            zip_ref.extractall(extract_to)\n","zip_path = '/kaggle/working/vistral.zip'  # Replace with your zip file path\n","extract_to = 'vistralfretrain'  # Replace with your extraction directory\n","\n","unzip_folder(zip_path, extract_to)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:00:03.774330Z","iopub.status.busy":"2024-05-19T16:00:03.773970Z","iopub.status.idle":"2024-05-19T16:00:04.254646Z","shell.execute_reply":"2024-05-19T16:00:04.253745Z","shell.execute_reply.started":"2024-05-19T16:00:03.774298Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>context</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?</td>\n","      <td>Tài liệu -  Quy định chung\\nV. QUẢN LÝ THÔNG T...</td>\n","      <td>Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ghét cái gì nhứt khi giao dịch trên GHTK?</td>\n","      <td>Tài liệu -  Quy định chung\\nVII. QUYỀN VÀ NGHĨ...</td>\n","      <td>Thật tiếc khi bạn cảm thấy ghét một điều gì đó...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?</td>\n","      <td>Tài liệu -  Quy định chung\\nV. QUẢN LÝ THÔNG T...</td>\n","      <td>Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thế cái vụ xâm nhập trái phép vào hệ thống GHT...</td>\n","      <td>Tài liệu -  Quy định chung\\nIII. QUY ĐỊNH ĐẢM ...</td>\n","      <td>Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...</td>\n","      <td>Tài liệu -  Quy định chung\\nIII. QUY ĐỊNH ĐẢM ...</td>\n","      <td>Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1061</th>\n","      <td>Có bao nhiêu cách thức để GHTK thông báo tình ...</td>\n","      <td>Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...</td>\n","      <td>Xin chào, rất vui được hỗ trợ bạn. Theo thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1062</th>\n","      <td>Mình thích nhận thông tin giao hàng của GHTK t...</td>\n","      <td>Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...</td>\n","      <td>Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...</td>\n","    </tr>\n","    <tr>\n","      <th>1063</th>\n","      <td>Mình muốn đăng ký dịch vụ thông báo tình trạng...</td>\n","      <td>Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...</td>\n","      <td>Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...</td>\n","    </tr>\n","    <tr>\n","      <th>1064</th>\n","      <td>Mình muốn nhận thông báo tình trạng đơn hàng t...</td>\n","      <td>Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...</td>\n","      <td>Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...</td>\n","    </tr>\n","    <tr>\n","      <th>1065</th>\n","      <td>Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...</td>\n","      <td>Tài liệu -  Quy định chung\\nI. Quy trình giao ...</td>\n","      <td>Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1066 rows × 3 columns</p>\n","</div>"],"text/plain":["                                               question  \\\n","0            Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?   \n","1             Ghét cái gì nhứt khi giao dịch trên GHTK?   \n","2            Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?   \n","3     Thế cái vụ xâm nhập trái phép vào hệ thống GHT...   \n","4     Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...   \n","...                                                 ...   \n","1061  Có bao nhiêu cách thức để GHTK thông báo tình ...   \n","1062  Mình thích nhận thông tin giao hàng của GHTK t...   \n","1063  Mình muốn đăng ký dịch vụ thông báo tình trạng...   \n","1064  Mình muốn nhận thông báo tình trạng đơn hàng t...   \n","1065  Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...   \n","\n","                                                context  \\\n","0     Tài liệu -  Quy định chung\\nV. QUẢN LÝ THÔNG T...   \n","1     Tài liệu -  Quy định chung\\nVII. QUYỀN VÀ NGHĨ...   \n","2     Tài liệu -  Quy định chung\\nV. QUẢN LÝ THÔNG T...   \n","3     Tài liệu -  Quy định chung\\nIII. QUY ĐỊNH ĐẢM ...   \n","4     Tài liệu -  Quy định chung\\nIII. QUY ĐỊNH ĐẢM ...   \n","...                                                 ...   \n","1061  Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...   \n","1062  Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...   \n","1063  Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...   \n","1064  Tài liệu - Chính sách giá\\nIV. DỊCH VỤ GIA TĂN...   \n","1065  Tài liệu -  Quy định chung\\nI. Quy trình giao ...   \n","\n","                                                 answer  \n","0     Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...  \n","1     Thật tiếc khi bạn cảm thấy ghét một điều gì đó...  \n","2     Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...  \n","3     Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...  \n","4     Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...  \n","...                                                 ...  \n","1061  Xin chào, rất vui được hỗ trợ bạn. Theo thông ...  \n","1062  Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...  \n","1063  Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...  \n","1064  Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...  \n","1065  Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...  \n","\n","[1066 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","\n","# Replace 'your_file.csv' with the path to your CSV file\n","file_path = 'chatbot.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Now you can work with the DataFrame 'df'\n","display(df)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:00:06.885504Z","iopub.status.busy":"2024-05-19T16:00:06.885140Z","iopub.status.idle":"2024-05-19T16:00:06.910652Z","shell.execute_reply":"2024-05-19T16:00:06.909722Z","shell.execute_reply.started":"2024-05-19T16:00:06.885474Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?\\nCh...</td>\n","      <td>Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ghét cái gì nhứt khi giao dịch trên GHTK?\\nChỉ...</td>\n","      <td>Thật tiếc khi bạn cảm thấy ghét một điều gì đó...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?\\nCh...</td>\n","      <td>Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thế cái vụ xâm nhập trái phép vào hệ thống GHT...</td>\n","      <td>Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...</td>\n","      <td>Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1061</th>\n","      <td>Có bao nhiêu cách thức để GHTK thông báo tình ...</td>\n","      <td>Xin chào, rất vui được hỗ trợ bạn. Theo thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1062</th>\n","      <td>Mình thích nhận thông tin giao hàng của GHTK t...</td>\n","      <td>Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...</td>\n","    </tr>\n","    <tr>\n","      <th>1063</th>\n","      <td>Mình muốn đăng ký dịch vụ thông báo tình trạng...</td>\n","      <td>Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...</td>\n","    </tr>\n","    <tr>\n","      <th>1064</th>\n","      <td>Mình muốn nhận thông báo tình trạng đơn hàng t...</td>\n","      <td>Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...</td>\n","    </tr>\n","    <tr>\n","      <th>1065</th>\n","      <td>Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...</td>\n","      <td>Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1066 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                 prompt  \\\n","0     Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?\\nCh...   \n","1     Ghét cái gì nhứt khi giao dịch trên GHTK?\\nChỉ...   \n","2     Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?\\nCh...   \n","3     Thế cái vụ xâm nhập trái phép vào hệ thống GHT...   \n","4     Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...   \n","...                                                 ...   \n","1061  Có bao nhiêu cách thức để GHTK thông báo tình ...   \n","1062  Mình thích nhận thông tin giao hàng của GHTK t...   \n","1063  Mình muốn đăng ký dịch vụ thông báo tình trạng...   \n","1064  Mình muốn nhận thông báo tình trạng đơn hàng t...   \n","1065  Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...   \n","\n","                                                 answer  \n","0     Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...  \n","1     Thật tiếc khi bạn cảm thấy ghét một điều gì đó...  \n","2     Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...  \n","3     Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...  \n","4     Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...  \n","...                                                 ...  \n","1061  Xin chào, rất vui được hỗ trợ bạn. Theo thông ...  \n","1062  Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...  \n","1063  Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...  \n","1064  Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...  \n","1065  Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...  \n","\n","[1066 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["prompt = 'Bạn là trợ lý AI lịch sử để trả lời các câu hỏi chăm sóc khách hàng của đơn vị vận chuyển Giao Hàng Tiết Kiệm'\n","prompt+= 'Bạn được cung cấp các nội dung được trích xuất sau đây của một tài liệu dài và một câu hỏi. Đưa ra câu trả lời đàm thoại.'\n","\n","prompt+= 'Nếu bạn không biết câu trả lời, chỉ cần nói \"Xin lỗi quý khách, nhưng tôi không tìm thấy thông tin liên quan đến dữ liệu được cung cấp.\" Đừng cố gắng bịa ra một câu trả lời.'\n","\n","prompt+= 'Hãy trả lời câu hỏi như thể bạn là nhân viên chăm sóc khách hàng lịch sự và niềm nở. Và chỉ trả lời ngắn gọn không quá 3 câu.'\n","\n","\n","df['prompt']=df['question']+'\\nChỉ dẫn : '+ prompt +'\\n' + df['context']\n","rd_df = df[['prompt', 'answer']]\n","display(rd_df)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def formatting_func(example):\n","    text = f\"### Câu trả lời: {example['answer']} \\n ### Câu hỏi : {example['prompt']}\"\n","    return text"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tớ hơi bí, cho tớ hỏi thử xem dịch vụ của GHTKPay là gì nào?\n","Chỉ dẫn : Bạn là trợ lý AI lịch sử để trả lời các câu hỏi chăm sóc khách hàng của đơn vị vận chuyển Giao Hàng Tiết KiệmBạn được cung cấp các nội dung được trích xuất sau đây của một tài liệu dài và một câu hỏi. Đưa ra câu trả lời đàm thoại.Nếu bạn không biết câu trả lời, chỉ cần nói \"Xin lỗi quý khách, nhưng tôi không tìm thấy thông tin liên quan đến dữ liệu được cung cấp.\" Đừng cố gắng bịa ra một câu trả lời.Hãy trả lời câu hỏi như thể bạn là nhân viên chăm sóc khách hàng lịch sự và niềm nở. Và chỉ trả lời ngắn gọn không quá 3 câu.\n","Tài liệu - Ví\n","A. ĐIỀU KHOẢN VÀ ĐIỀU KIỆN SỬ DỤNG DỊCH VỤ\n","ĐIỀU 1. GIỚI THIỆU DỊCH VỤ\n","1.1. Công ty Cổ phần GHTKPAY là doanh nghiệp cung ứng dịch vụ trung gian thanh toán hoạt động theo Giấy phép số 02/GP-NHNN do Ngân hàng Nhà nước Việt Nam ký ngày 27/01/2022.\n","1.2. GHTKPay cung cấp (i) tính năng cho phép Khách hàng sử dụng tài khoản thanh toán/thẻ ngân hàng/Ví điện tử GHTKPay để thanh toán hàng hóa/dịch vụ; (ii) tính năng cho phép \n","ĐVCNTT chấp nhận thanh toán và nhận doanh thu hàng hóa/dịch vụ thông qua Ví điện tử GHTKPay của ĐVCNTT hoặc tài khoản ngân hàng của ĐVCNTT; và (iii) các tính năng khác phù hợp với quy định của pháp luật trong từng thời kỳ.\n","1.3. Dịch vụ GHTKPay có thể được tích hợp trên Ứng dụng (“App mobile” hoặc “App”) hoặc Website (“Web”) của Bên thứ ba. Khi sử dụng Dịch vụ GHTKPay trên App/Web của Bên thứ ba, Khách hàng đồng thời đồng ý và sẽ tuân thủ các điều khoản dịch vụ của Bên thứ ba đó. Khách hàng cũng đồng ý rằng GHTKPay không chịu trách nhiệm vềdịch vụ của Bên thứ ba và/hoặc tính chính xác của hàng hóa/dịch vụ, bao gồm nhưng không giới hạn bởi các chức năng, độ tin cậy, an ninh, chính sách bảo mật hoặc các hoạt động khác của các App/Web của Bên thứ ba đó. Căn cứ theo thỏa thuận và yêu cầu của Bên thứ ba, GHTKPay có thể đưa ra một hoặc một số tính năng Dịch vụ GHTKPay nhất định. Một hoặc một số tính năng này sẽ tương ứng, phù hợp với nhu cầu hợp tác, mô hình kinh doanh của Bên thứ ba và không trái với quy định của pháp luật.\n","\n","Tài liệu - Ví\n","B. CHÍNH SÁCH BẢO MẬT\n","2. THU THẬP THÔNG TIN\n","2.2. Thông tin thu thập bởi GHTKPay:\n","Khi Bên sử dụng dịch vụ truy cập website/ứng dụng hoặc sử dụng Dịch vụ GHTKPay, GHTKPay có thể sử dụng các công nghệ để thu thập thông tin như sau:\n","a.        Log data: Khi Bên sử dụng dịch vụ truy cập website/ứng dụng hoặc sử dụng Dịch vụ, hệ thống của GHTKPay sẽ tự động thu thập và lưu trữ các thông tin bao gồm:\n","-        Địa chỉ IP (Internet Protocol).\n","-        Hệ điều hành của máy tính/thiết bị di động, loại trình duyệt, loại thiết bị di động, các đặc điểm như mã định danh thiết bị di động (MEID).\n","-        Các webiste/ứng dụng mà Bên sử dụng dịch vụ đã truy cập và chuyển đến tham chiếu Dịch vụ của GHTKPay.\n","-        Thời gian truy cập sử dụng Dịch vụ.\n","-        Và các thông tin khác được chúng tôi thu thập để đưa vào số liệu thống kê, hiểu được khách hàng, từ đó đưa ra các tiện ích dịch vụ phù hợp với nhu cầu sử dụng.\n","b.        Cookies: cookie là một tập tin mà GHTKPay gửi tới thiết bị của Bên sử dụng dịch vụ để lưu trữ thông tin. Thông qua cookie, GHTKPay có thể lưu mã định danh (ID) và mật khẩu đã đăng ký bởi Bên sử dụng dịch vụ để sử dụng cho việc đăng nhập tự động các lần sau đó, ngoài ra, GHTKPay có thể kích hoạt một số tính năng nhất định của Dịch vụ và website/ứng dụng để hiểu rõ hơn về cách Bên sử dụng dịch vụ tương tác và sử dụng Dịch vụ GHTKPay. Cookies mà chúng tôi sử dụng có thể bao gồm (1) cookie được lưu lại trên máy của Bên sử dụng dịch vụ, và (2) cookie được xóa sau khi Bên sử dụng dịch vụ đăng xuất khỏi Dịch vụ và đóng trình duyệt/ứng dụng. Bên sử dụng dịch vụ có thể từ chối sử dụng cookie bằng cách chọn thiết lập thích hợp trên trình duyệt hoặc thiết bị di động. Tuy nhiên, cùng với đó, Bên sử dụng dịch vụ sẽ có thể không được sử dụng với đầy đủ các tính năng và tiện ích của Dịch vụ GHTKPay.\n","c.        Cấp quyền trên thiết bị di động để chia sẻ thông tin với GHTKPay: Bên sử dụng dịch vụ có thể sử dụng các thiết bị điện thoại để cài đặt các tính năng liên quan đến “Quyền riêng tư và Bảo mật” theo chính sách của nhà cung cấp thiết bị di động. Để làm rõ, các dữ liệu này cần phải được sự đồng ý của Bên sử dụng dịch vụ và có thể bao gồm các dữ liệu sau:\n","-        Dịch vụ định vị: người sử dụng có quyền cho phép GHTKPay truy cập vị trí hay không ở các mục “Không”, “Hỏi lần sau hoặc khi tôi chia sẻ”, “Khi dùng Ứng dụng”, “Khi dùng ứng dụng hoặc tiện ích”, người sử dụng có thể bật tính năng vị trí chính xác. GHTKPay khuyến khích Bên sử dụng dịch vụ bật tính năng cho phép GHTKPay truy cập vị trí “Khi dùng Ứng dụng” để nâng cao chất lượng dịch vụ.\n","-        Theo dõi: Là tính năng cho phép ứng dụng theo dõi hoạt động của người sử dụng thiết bị trên các ứng dụng và website của các công ty khác. Để đảm bảo an toàn bảo mật, GHTKPay không yêu cầu tính năng này.\n","-        Danh bạ điện thoại: Để hỗ trợ tốt nhất cho Bên sử dụng dịch vụ, GHTKPay có thể yêu cầu tính năng này. GHTKPay cam kết sẽ tôn trọng và không sử dụng danh bạ điện thoại đó cho bất kỳ mục đích nào nếu không có sự đồng ý của Bên sử dụng dịch vụ.\n","-        Ảnh trên thiết bị di động: người sử dụng có quyền cho phép GHTKPay truy cập ảnh hay không ở các mục “Ảnh được chọn”, “Tất cả ảnh”, “Không có”. Quyền truy cập vào ảnh bao gồm cả dữ liệu liên quan ví dụ như thông tin vị trí chụp ảnh, ngày chụp. GHTKPay khuyến khích Bên sử dụng dịch vụ bật tính năng cho phép GHTKPay truy cập “Ảnh được chọn”.\n","-        Micro: Trong trường hợp GHTKPay triển khai dịch vụ chăm sóc khách hàng trực tiếp trên ứng dụng gồm nhắn tin, gọi điện thì GHTKPay có thể sẽ yêu cầu cấp quyền micro từ thiết bị của Bên sử dụng dịch vụ.\n","-        Camera: Ảnh và video được chụp/quay bằng camera có thể chứa các thông tin như địa điểm, thời gian chụp, quay. GHTKPay cần truy cập camera của Bên sử dụng dịch vụ để tiến hành việc định danh khách hàng theo quy định của pháp luật.\n","-        Các trường hợp trên không nhằm mục đích liệt kê đầy đủ các trường hợp và chỉ đưa ra một số trường hợp phổ biến có thể được GHTKPay xử lý dữ liệu sau khi được sự đồng ý cài đặt trên thiết bị di dộng của Bên sử dụng dịch vụ.\n","d.        Và/hoặc các công nghệ khác phát triển trong từng thời kỳ\n","\n","Tài liệu - Ví\n","B. CHÍNH SÁCH BẢO MẬT\n","2. THU THẬP THÔNG TIN\n","GHTKPay thu thập thông tin bằng nhiều cách khác nhau, bao gồm các cách thức như:\n","-\tCác mẫu đăng ký sử dụng dịch vụ trên các website/ứng dụng. Các mẫu này gồm đăng ký mở Ví điện tử; đăng ký sử dụng dịch vụ ví mua trước trả sau; đăng ký sử dụng dịch vụ ứng trước tiền hàng; thoả thuận sử dụng dịch vụ hỗ trợ thu hộ, chi hộ; các Hợp đồng/Thoả thuận khác do GHTKPay phát triển dịch vụ, phù hợp với quy định của pháp luật trong từng thời kỳ.\n","-\tCác giao dịch thanh toán, chuyển tiền, nạp tiền, rút tiền thông qua Dịch vụ GHTKPay.\n","-\tCác thông tin khác thu thập trong quá trình vận hành Dịch vụ GHTKPay như Bên sử dụng dịch vụ tương tác qua các cuộc gọi điện thoại (có thể được ghi âm); gặp gỡ trực tiếp; cung cấp ý kiến/phản hồi/phản ánh/khiếu nại đến GHTKPay; đăng ký tham gia các chương trình khuyến mại, các chương trình thi có thưởng; các hoạt động khác khi truy cập Ví điện tử; các dữ liệu phù hợp khác mà Bên sử dụng dịch vụ cung cấp cho GHTKPay.\n","-\tCác công nghệ như log data, cookies, cấp quyền trên thiết bị di động để chia sẻ thông tin với GHTKPay và/hoặc các công nghệ khác phát triển trong từng thời kỳ.\n","-\tCác trường hợp trên không nhằm mục đích liệt kê đầy đủ các trường hợp và chỉ đưa ra một số trường hợp phổ biến có thể được GHTKPay xử lý dữ liệu.\n","Các thông tin mà GHTKPay xử lý dữ liệu theo quy định tại Khoản 1.1 Điều 1 của Chính sách bảo mật này gồm các dữ liệu cá nhân cơ bản và dữ liệu cá nhân nhạy cảm được liệt kê dưới đây:\n"]}],"source":["print(df['prompt'].iloc[10])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install peft"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install trl"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mlflow\n","  Downloading mlflow-2.12.2-py3-none-any.whl.metadata (29 kB)\n","Collecting Flask<4 (from mlflow)\n","  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n","Collecting alembic!=1.10.0,<2 (from mlflow)\n","  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting click<9,>=7.0 (from mlflow)\n","  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n","Collecting cloudpickle<4 (from mlflow)\n","  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n","Collecting docker<8,>=4.0.0 (from mlflow)\n","  Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n","Collecting entrypoints<1 (from mlflow)\n","  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n","Collecting gitpython<4,>=3.1.9 (from mlflow)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Collecting graphene<4 (from mlflow)\n","  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n","Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (7.0.0)\n","Requirement already satisfied: markdown<4,>=3.3 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (3.5.1)\n","Requirement already satisfied: matplotlib<4 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (3.8.2)\n","Requirement already satisfied: numpy<2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (1.26.2)\n","Requirement already satisfied: packaging<25 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (23.2)\n","Requirement already satisfied: pandas<3 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (2.1.3)\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (4.25.3)\n","Collecting pyarrow<16,>=4.0.0 (from mlflow)\n","  Downloading pyarrow-15.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: pytz<2025 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (2023.3.post1)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (6.0.1)\n","Collecting querystring-parser<2 (from mlflow)\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n","Requirement already satisfied: requests<3,>=2.17.3 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (2.31.0)\n","Requirement already satisfied: scikit-learn<2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (1.3.2)\n","Requirement already satisfied: scipy<2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (1.11.4)\n","Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n","  Downloading SQLAlchemy-2.0.30-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Collecting sqlparse<1,>=0.4.0 (from mlflow)\n","  Downloading sqlparse-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from mlflow) (3.1.4)\n","Collecting gunicorn<23 (from mlflow)\n","  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.10.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from docker<8,>=4.0.0->mlflow) (2.1.0)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from Flask<4->mlflow) (3.0.1)\n","Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow)\n","  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting blinker>=1.6.2 (from Flask<4->mlflow)\n","  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n","Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n","  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: zipp>=0.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.4.5)\n","Requirement already satisfied: pillow>=8 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from matplotlib<4->mlflow) (6.1.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from pandas<3->mlflow) (2023.3)\n","Requirement already satisfied: six in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from querystring-parser<2->mlflow) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n","Requirement already satisfied: joblib>=1.1.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (3.2.0)\n","Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=1.4.0->mlflow)\n","  Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading mlflow-2.12.2-py3-none-any.whl (20.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n","Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n","Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-15.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Downloading SQLAlchemy-2.0.30-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sqlparse-0.5.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n","Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.8/660.8 kB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: aniso8601, sqlparse, smmap, querystring-parser, pyarrow, Mako, itsdangerous, gunicorn, greenlet, graphql-core, entrypoints, cloudpickle, click, blinker, sqlalchemy, graphql-relay, gitdb, Flask, docker, graphene, gitpython, alembic, mlflow\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 16.1.0\n","    Uninstalling pyarrow-16.1.0:\n","      Successfully uninstalled pyarrow-16.1.0\n","Successfully installed Flask-3.0.3 Mako-1.3.5 alembic-1.13.1 aniso8601-9.0.1 blinker-1.8.2 click-8.1.7 cloudpickle-3.0.0 docker-7.0.0 entrypoints-0.4 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 greenlet-3.0.3 gunicorn-22.0.0 itsdangerous-2.2.0 mlflow-2.12.2 pyarrow-15.0.2 querystring-parser-1.2.4 smmap-5.0.1 sqlalchemy-2.0.30 sqlparse-0.5.0\n"]}],"source":["!pip install mlflow"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install accelerate"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple/\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: scipy in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from bitsandbytes) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from scipy->bitsandbytes) (1.26.2)\n","Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.42.0\n"]}],"source":["!pip install -i https://pypi.org/simple/ bitsandbytes"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:00:20.803582Z","iopub.status.busy":"2024-05-19T16:00:20.803205Z","iopub.status.idle":"2024-05-19T16:00:29.660994Z","shell.execute_reply":"2024-05-19T16:00:29.660165Z","shell.execute_reply.started":"2024-05-19T16:00:20.803552Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-20 10:17:36.516833: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-05-20 10:17:36.635969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-20 10:17:36.636078: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-20 10:17:36.636265: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-20 10:17:36.672968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import evaluate\n","import numpy as np\n","\n","metric = evaluate.load(\"bleu\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:00:34.226947Z","iopub.status.busy":"2024-05-19T16:00:34.226265Z","iopub.status.idle":"2024-05-19T16:00:34.233904Z","shell.execute_reply":"2024-05-19T16:00:34.232712Z","shell.execute_reply.started":"2024-05-19T16:00:34.226915Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_preds):\n","    logit, labels = eval_preds\n","    predictions = np.argmax(logit,axis=-1)\n","    true_labels = [\" \".join(str(l) for l in label if l != -100) for label in labels]\n","    true_predictions = [\n","    \" \".join(str(p) for (p, l) in zip(prediction, label) if l != -100)\n","    for prediction, label in zip(predictions, labels)\n","]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return { 'bleu':all_metrics[\"bleu\"],\n","            'precisions':all_metrics[\"precisions\"],\n","            'brevity_penalty':all_metrics[\"brevity_penalty\"],}"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:00:36.690003Z","iopub.status.busy":"2024-05-19T16:00:36.689608Z","iopub.status.idle":"2024-05-19T16:01:21.500986Z","shell.execute_reply":"2024-05-19T16:01:21.498584Z","shell.execute_reply.started":"2024-05-19T16:00:36.689971Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?\\nCh...</td>\n","      <td>Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ghét cái gì nhứt khi giao dịch trên GHTK?\\nChỉ...</td>\n","      <td>Thật tiếc khi bạn cảm thấy ghét một điều gì đó...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?\\nCh...</td>\n","      <td>Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thế cái vụ xâm nhập trái phép vào hệ thống GHT...</td>\n","      <td>Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...</td>\n","      <td>Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1061</th>\n","      <td>Có bao nhiêu cách thức để GHTK thông báo tình ...</td>\n","      <td>Xin chào, rất vui được hỗ trợ bạn. Theo thông ...</td>\n","    </tr>\n","    <tr>\n","      <th>1062</th>\n","      <td>Mình thích nhận thông tin giao hàng của GHTK t...</td>\n","      <td>Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...</td>\n","    </tr>\n","    <tr>\n","      <th>1063</th>\n","      <td>Mình muốn đăng ký dịch vụ thông báo tình trạng...</td>\n","      <td>Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...</td>\n","    </tr>\n","    <tr>\n","      <th>1064</th>\n","      <td>Mình muốn nhận thông báo tình trạng đơn hàng t...</td>\n","      <td>Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...</td>\n","    </tr>\n","    <tr>\n","      <th>1065</th>\n","      <td>Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...</td>\n","      <td>Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1066 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                 prompt  \\\n","0     Ghét nhắm! Sàn TMĐT GHTK cấm nháy mắt nào?\\nCh...   \n","1     Ghét cái gì nhứt khi giao dịch trên GHTK?\\nChỉ...   \n","2     Hành vi nào bị cấm trên sàn TMĐT GHTK nhỉ?\\nCh...   \n","3     Thế cái vụ xâm nhập trái phép vào hệ thống GHT...   \n","4     Tấm chiếu mới mà cũng bị cấm nhúng tay nhúng c...   \n","...                                                 ...   \n","1061  Có bao nhiêu cách thức để GHTK thông báo tình ...   \n","1062  Mình thích nhận thông tin giao hàng của GHTK t...   \n","1063  Mình muốn đăng ký dịch vụ thông báo tình trạng...   \n","1064  Mình muốn nhận thông báo tình trạng đơn hàng t...   \n","1065  Tớ muốn biết tình trạng đơn hàng thì GHTK gửi ...   \n","\n","                                                 answer  \n","0     Thật xin lỗi, tôi không tìm thấy bất kỳ thông ...  \n","1     Thật tiếc khi bạn cảm thấy ghét một điều gì đó...  \n","2     Chào bạn, rất vui được hỗ trợ bạn.\\n\\nTheo quy...  \n","3     Thưa quý khách, cảm ơn quý khách đã liên hệ vớ...  \n","4     Thưa anh/chị,\\nNhững thông tin anh/chị cung cấ...  \n","...                                                 ...  \n","1061  Xin chào, rất vui được hỗ trợ bạn. Theo thông ...  \n","1062  Chào bạn, bạn hoàn toàn có thể sở hữu cho mình...  \n","1063  Thân chào anh/chị,\\n\\nVề dịch vụ thông báo tìn...  \n","1064  Chào bạn,\\n\\nCảm ơn bạn đã lựa chọn dịch vụ Gi...  \n","1065  Chào bạn, nếu bạn muốn biết tình trạng đơn hàn...  \n","\n","[1066 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n","Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.78s/it]\n","/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Generating train split: 1621 examples [00:01, 1299.58 examples/s]\n","Generating train split: 80 examples [00:00, 1364.33 examples/s]\n","/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n","/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3268' max='4863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3268/4863 2:12:20 < 1:04:38, 0.41 it/s, Epoch 2.02/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Precisions</th>\n","      <th>Brevity Penalty</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>1.660400</td>\n","      <td>1.525091</td>\n","      <td>0.440704</td>\n","      <td>[0.80858154296875, 0.5018695014662756, 0.3519324853228963, 0.264128305582762]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.368000</td>\n","      <td>1.148061</td>\n","      <td>0.551138</td>\n","      <td>[0.8507080078125, 0.601001955034213, 0.46884784735812135, 0.3849045053868756]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.010400</td>\n","      <td>0.789743</td>\n","      <td>0.656859</td>\n","      <td>[0.88568115234375, 0.6977150537634409, 0.5885029354207436, 0.5119000979431929]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.698000</td>\n","      <td>0.536712</td>\n","      <td>0.758324</td>\n","      <td>[0.91607666015625, 0.7873655913978495, 0.7074853228962819, 0.6480288932419197]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.484700</td>\n","      <td>0.389638</td>\n","      <td>0.821698</td>\n","      <td>[0.935693359375, 0.8424731182795699, 0.7833292563600783, 0.7382713026444662]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.362400</td>\n","      <td>0.301137</td>\n","      <td>0.860942</td>\n","      <td>[0.9468017578125, 0.8762585532746823, 0.8311888454011742, 0.7967189030362389]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.290700</td>\n","      <td>0.244535</td>\n","      <td>0.885341</td>\n","      <td>[0.9540771484375, 0.8973729227761486, 0.8613258317025441, 0.83314152791381]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.246600</td>\n","      <td>0.212324</td>\n","      <td>0.899976</td>\n","      <td>[0.95888671875, 0.9101417399804497, 0.8792441291585127, 0.8549461312438785]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.191100</td>\n","      <td>0.199746</td>\n","      <td>0.905682</td>\n","      <td>[0.96103515625, 0.9151515151515152, 0.8860567514677103, 0.8633937316356514]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.169500</td>\n","      <td>0.186927</td>\n","      <td>0.912592</td>\n","      <td>[0.96304931640625, 0.9209799608993158, 0.8945572407045009, 0.8741797257590598]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.175100</td>\n","      <td>0.178837</td>\n","      <td>0.916640</td>\n","      <td>[0.96409912109375, 0.9243401759530792, 0.8996086105675146, 0.8806194906953967]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.171400</td>\n","      <td>0.170973</td>\n","      <td>0.920097</td>\n","      <td>[0.96571044921875, 0.9274926686217009, 0.9036325831702544, 0.8854921645445641]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.164400</td>\n","      <td>0.167398</td>\n","      <td>0.920944</td>\n","      <td>[0.96622314453125, 0.9282991202346041, 0.9046722113502935, 0.886496082272282]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.154600</td>\n","      <td>0.162962</td>\n","      <td>0.922789</td>\n","      <td>[0.96644287109375, 0.929875366568915, 0.9070450097847358, 0.8895690499510284]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.153000</td>\n","      <td>0.158923</td>\n","      <td>0.925662</td>\n","      <td>[0.9675537109375, 0.9324169110459433, 0.9105675146771037, 0.8937438785504408]</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.135800</td>\n","      <td>0.156146</td>\n","      <td>0.926112</td>\n","      <td>[0.9678466796875, 0.932820136852395, 0.9110078277886497, 0.8943927522037218]</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[0.80858154296875, 0.5018695014662756, 0.3519324853228963, 0.264128305582762]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.80858154296875, 0.5018695014662756, 0.3519324853228963, 0.264128305582762]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8507080078125, 0.601001955034213, 0.46884784735812135, 0.3849045053868756]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8507080078125, 0.601001955034213, 0.46884784735812135, 0.3849045053868756]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.88568115234375, 0.6977150537634409, 0.5885029354207436, 0.5119000979431929]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.88568115234375, 0.6977150537634409, 0.5885029354207436, 0.5119000979431929]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.91607666015625, 0.7873655913978495, 0.7074853228962819, 0.6480288932419197]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.91607666015625, 0.7873655913978495, 0.7074853228962819, 0.6480288932419197]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.935693359375, 0.8424731182795699, 0.7833292563600783, 0.7382713026444662]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.935693359375, 0.8424731182795699, 0.7833292563600783, 0.7382713026444662]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9468017578125, 0.8762585532746823, 0.8311888454011742, 0.7967189030362389]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9468017578125, 0.8762585532746823, 0.8311888454011742, 0.7967189030362389]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9540771484375, 0.8973729227761486, 0.8613258317025441, 0.83314152791381]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9540771484375, 0.8973729227761486, 0.8613258317025441, 0.83314152791381]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.95888671875, 0.9101417399804497, 0.8792441291585127, 0.8549461312438785]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.95888671875, 0.9101417399804497, 0.8792441291585127, 0.8549461312438785]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","Trainer is attempting to log a value of \"[0.96103515625, 0.9151515151515152, 0.8860567514677103, 0.8633937316356514]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96103515625, 0.9151515151515152, 0.8860567514677103, 0.8633937316356514]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96304931640625, 0.9209799608993158, 0.8945572407045009, 0.8741797257590598]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96304931640625, 0.9209799608993158, 0.8945572407045009, 0.8741797257590598]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96409912109375, 0.9243401759530792, 0.8996086105675146, 0.8806194906953967]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96409912109375, 0.9243401759530792, 0.8996086105675146, 0.8806194906953967]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96571044921875, 0.9274926686217009, 0.9036325831702544, 0.8854921645445641]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96571044921875, 0.9274926686217009, 0.9036325831702544, 0.8854921645445641]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96622314453125, 0.9282991202346041, 0.9046722113502935, 0.886496082272282]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96622314453125, 0.9282991202346041, 0.9046722113502935, 0.886496082272282]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96644287109375, 0.929875366568915, 0.9070450097847358, 0.8895690499510284]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.96644287109375, 0.929875366568915, 0.9070450097847358, 0.8895690499510284]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9675537109375, 0.9324169110459433, 0.9105675146771037, 0.8937438785504408]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9675537109375, 0.9324169110459433, 0.9105675146771037, 0.8937438785504408]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9678466796875, 0.932820136852395, 0.9110078277886497, 0.8943927522037218]\" of type <class 'list'> for key \"eval_precisions\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.9678466796875, 0.932820136852395, 0.9110078277886497, 0.8943927522037218]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"]}],"source":["from datasets import load_dataset\n","from trl import SFTTrainer\n","from peft import LoraConfig\n","import peft\n","from transformers import LlamaTokenizer, LlamaForCausalLM\n","\n","\n","display(rd_df), rd_df.shape\n","\n","# COMMAND ----------\n","\n","from datasets import load_dataset\n","from datasets import Dataset\n","dataset = Dataset.from_pandas(rd_df).train_test_split(test_size=0.05, seed=42)\n","\n","target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head']\n","#or\n","# target_modules = ['q_proj','v_proj']\n","base_dir = \"<base_dir_location>\"\n","\n","per_device_train_batch_size = 1\n","gradient_accumulation_steps = 1\n","optim = 'adamw_hf'\n","learning_rate = 1e-5\n","warmup_ratio= 0.1\n","lr_scheduler_type = \"linear\"\n","lora_config = LoraConfig(\n","    r=8,#or r=16\n","    lora_alpha=8,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    target_modules = target_modules,\n","    task_type=\"CAUSAL_LM\",\n",")\n","from transformers import TrainingArguments\n","training_args = TrainingArguments(\n","    output_dir=base_dir,\n","    save_strategy=\"epoch\",\n","    evaluation_strategy=\"steps\",\n","    logging_steps=200,\n","    eval_steps=200,\n","    num_train_epochs = 3.0,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    learning_rate=learning_rate,\n","#     fp16=True,\n","    warmup_ratio=warmup_ratio,\n","    group_by_length=True,\n","    lr_scheduler_type=lr_scheduler_type,\n",")\n","model = LlamaForCausalLM.from_pretrained(\n","    \"Viet-Mistral/Vistral-7B-Chat\",  load_in_4bit=True, device_map='auto',\n",")\n","# model.add_adapter(lora_config, adapter_name=\"adapter_1\")\n","trainer = SFTTrainer(\n","    model,\n","    train_dataset=dataset['train'],\n","    eval_dataset = dataset['test'],\n","    packing=True,\n","    formatting_func=formatting_func,\n","    peft_config=lora_config,\n","    max_seq_length=1024,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -U huggingface_hub"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /home/trungct/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"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\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import LlamaTokenizer, LlamaForCausalLM,AutoModelForCausalLM,AutoTokenizer\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    'Viet-Mistral/Vistral-7B-Chat', load_in_8bit=True, device_map='auto',\n",")\n","tokenizer = LlamaTokenizer.from_pretrained(\"Viet-Mistral/Vistral-7B-Chat\")\n","prompt = 'Gửi hàng bằng GHTK kiểu gì nhỉ'\n","input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n","\n","generation_output = model.generate(\n","  input_ids=input_ids, max_new_tokens=128\n",")\n","generation_output\n","predictions=[]\n","predictions.append(tokenizer.decode(generation_output[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -i https://pypi.org/simple/ bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stderr","output_type":"stream","text":["/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[    1,   774, 36508,  ...,  9602, 28723, 28705]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}\n"]},{"name":"stderr","output_type":"stream","text":["/home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n","2024-05-20 13:27:34.857081: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-05-20 13:27:34.959255: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-20 13:27:34.959335: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-20 13:27:34.959539: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-20 13:27:34.997147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["tensor([[    1,   774, 36508,  ..., 28723, 28705,     2]], device='cuda:0')\n","Assistant:  \n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[    1,   774, 36508,  ...,  9602, 28723, 28705]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}\n","tensor([[    1,   774, 36508,  ..., 28723, 28705,     2]], device='cuda:0')\n","Assistant:  \n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[    1,   774, 36508, 33668,   714, 33228, 32405, 35004, 38020, 36465,\n","         38114, 37637, 32714, 36409, 36208, 28738, 28796,  9602, 35511, 28804,\n","            13, 33001, 37754,   714, 35122, 26941, 37087, 36684, 16107, 32204,\n","         37342, 36810, 37007, 32671, 37312, 33600, 33668, 33866, 36283, 32908,\n","         34497, 33069, 37693, 32711, 34286, 35757, 28724, 32834, 32436, 34726,\n","         32985,   524, 37354, 32776, 35004, 32432, 36095, 37312, 35774, 37944,\n","         35004, 35106, 34762, 10241, 32191, 33069, 37045, 33246, 33968, 37881,\n","         35690, 37045, 33600, 33668, 28723, 38299, 13419, 33600, 37007, 32671,\n","         36612, 33885, 28723, 36030, 35156, 35979, 35734, 33600, 37007, 32671,\n","         28725, 37563, 38362, 36411,   345, 37869, 36986, 34938, 32908, 28725,\n","         33585, 35197, 35979, 34044, 36299, 33359, 17089, 33875, 34407, 33969,\n","         36114, 33968, 35004, 32432, 36095,   611, 38271, 36394, 35281,   287,\n","         35625, 13419, 37045, 33600, 37007, 32671, 28723, 34042, 37007, 32671,\n","         33600, 33668, 32177, 35307, 35156, 26941, 37046, 34850, 33866, 36283,\n","         32908, 34497, 34775, 32204, 36065, 35690, 38230, 32892, 28723, 33278,\n","         37563, 37007, 32671, 16937, 38079, 34703, 35979, 34529, 28705, 28770,\n","         33600, 28723, 36508, 33668,   714,    13, 28705]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n","       device='cuda:0')}\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/trungct/Duyborrow/notebook/chatfrbot.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(conversation, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(inputs)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m out_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49minputs[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m768\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49m\u001b[39m1.05\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(out_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.106.71/home/trungct/Duyborrow/notebook/chatfrbot.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m assistant \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mbatch_decode(out_ids[:, inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m): ], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstrip()\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/generation/utils.py:1736\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1729\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1730\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1731\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1732\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1733\u001b[0m     )\n\u001b[1;32m   1735\u001b[0m     \u001b[39m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1736\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample(\n\u001b[1;32m   1737\u001b[0m         input_ids,\n\u001b[1;32m   1738\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mprepared_logits_processor,\n\u001b[1;32m   1739\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mprepared_logits_warper,\n\u001b[1;32m   1740\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mprepared_stopping_criteria,\n\u001b[1;32m   1741\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[1;32m   1742\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1743\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1744\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1745\u001b[0m     )\n\u001b[1;32m   1747\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39min\u001b[39;00m (GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1748\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m     prepared_logits_warper \u001b[39m=\u001b[39m (\n\u001b[1;32m   1750\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config) \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mdo_sample \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/generation/utils.py:2375\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2372\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2374\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2375\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2376\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2377\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2378\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2379\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2380\u001b[0m )\n\u001b[1;32m   2382\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2383\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1136\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1138\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1140\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1141\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1142\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1143\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1144\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1145\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1146\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1147\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1148\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[1;32m   1151\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1152\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py:1024\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1015\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1016\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         use_cache,\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1024\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1025\u001b[0m         hidden_states,\n\u001b[1;32m   1026\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1027\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1028\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1030\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1031\u001b[0m     )\n\u001b[1;32m   1033\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py:738\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    735\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    737\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 738\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    739\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    740\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    741\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    742\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    743\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    744\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    745\u001b[0m )\n\u001b[1;32m    746\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    748\u001b[0m \u001b[39m# Fully Connected\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py:640\u001b[0m, in \u001b[0;36mMistralSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    637\u001b[0m bsz, q_len, _ \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39msize()\n\u001b[1;32m    639\u001b[0m query_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 640\u001b[0m key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj(hidden_states)\n\u001b[1;32m    641\u001b[0m value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj(hidden_states)\n\u001b[1;32m    643\u001b[0m query_states \u001b[39m=\u001b[39m query_states\u001b[39m.\u001b[39mview(bsz, q_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:474\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(lora_A\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_dora[active_adapter]:\n\u001b[0;32m--> 474\u001b[0m     output \u001b[39m=\u001b[39m lora_B(lora_A(dropout(x))) \u001b[39m*\u001b[39m scaling\n\u001b[1;32m    475\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_dora(x, lora_A, lora_B, scaling, active_adapter)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","prompt = 'Bạn là trợ lý AI lịch sử để trả lời các câu hỏi chăm sóc khách hàng của đơn vị vận chuyển Giao Hàng Tiết Kiệm'\n","prompt+= 'Bạn được cung cấp các nội dung được trích xuất sau đây của một tài liệu dài và một câu hỏi. Đưa ra câu trả lời đàm thoại.'\n","\n","prompt+= 'Nếu bạn không biết câu trả lời, chỉ cần nói \"Xin lỗi quý khách, nhưng tôi không tìm thấy thông tin liên quan đến dữ liệu được cung cấp.\" Đừng cố gắng bịa ra một câu trả lời.'\n","\n","prompt+= 'Hãy trả lời câu hỏi như thể bạn là nhân viên chăm sóc khách hàng rất lịch sự và niềm nở. Và chỉ trả lời ngắng gọn không quá 3 câu. Câu hỏi :'\n","\n","tokenizer = AutoTokenizer.from_pretrained('Viet-Mistral/Vistral-7B-Chat')\n","model = AutoModelForCausalLM.from_pretrained(\n","    '/home/trungct/Duyborrow/notebook/<base_dir_location>/checkpoint-3242', load_in_4bit=True, device_map='auto',\n",")\n","\n","# conversation = [{\"role\": \"system\", \"content\": prompt }]\n","while True:\n","    human = input(\"Human: \")\n","    rule = input(\"Rules: \")\n","    # if human.lower() == \"reset\":\n","    #     conversation = [{\"role\": \"system\", \"content\": prompt }]\n","    #     print(\"The chat history has been cleared!\")\n","    #     continue\n","\n","    conversation = '### Câu hỏi : {human}\\n Chỉ dẫn : {prompt}\\n{rules} '.format(human=human, prompt= prompt, rules = rule)\n","    inputs = tokenizer(conversation, return_tensors=\"pt\").to(model.device)\n","    print(inputs)\n","    \n","    out_ids = model.generate(\n","        input_ids=inputs['input_ids'],\n","        max_new_tokens=768,\n","        do_sample=True,\n","        top_p=0.95,\n","        top_k=40,\n","        temperature=0.1,\n","        repetition_penalty=1.05,\n","    )\n","    print(out_ids)\n","    assistant = tokenizer.batch_decode(out_ids[:, inputs['input_ids'].size(1): ], skip_special_tokens=True)[0].strip()\n","    print(\"Assistant: \", assistant) \n","    # conversation.append({\"role\": \"assistant\", \"content\": assistant })"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import zipfile\n","\n","def zip_folder(folder_path, output_path):\n","    \"\"\"\n","    Zip the contents of an entire folder (with that folder included in the archive).\n","    \n","    :param folder_path: Path to the folder to zip.\n","    :param output_path: Path for the output zip file.\n","    \"\"\"\n","    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        # Walk the directory\n","        for root, dirs, files in os.walk(folder_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                arcname = os.path.relpath(file_path, start=folder_path)\n","                zipf.write(file_path, arcname=arcname)\n","\n","# Example usage:\n","folder_to_zip = '/kaggle/working/<base_dir_location>/checkpoint-3036'\n","output_zip = '/kaggle/working/vistal.zip'\n","zip_folder(folder_to_zip, output_zip)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (2.19.1)\n","Requirement already satisfied: numpy>=1.17 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (1.26.2)\n","Requirement already satisfied: dill in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (2.1.3)\n","Requirement already satisfied: requests>=2.19.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (0.23.0)\n","Requirement already satisfied: packaging in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from evaluate) (23.2)\n","Requirement already satisfied: filelock in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /home/trungct/miniconda3/envs/keras/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.2\n"]}],"source":["!pip install evaluate"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":4}
